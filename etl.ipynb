{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6257f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: inserted 100 rows (total=100)\n",
      "Page 2: inserted 100 rows (total=200)\n",
      "Page 3: inserted 100 rows (total=300)\n",
      "Page 4: inserted 100 rows (total=400)\n",
      "Page 5: inserted 100 rows (total=500)\n",
      "Page 6: inserted 100 rows (total=600)\n",
      "Page 7: inserted 100 rows (total=700)\n",
      "Page 8: inserted 100 rows (total=800)\n",
      "Page 9: inserted 100 rows (total=900)\n",
      "Page 10: inserted 100 rows (total=1000)\n",
      "Page 11: inserted 100 rows (total=1100)\n",
      "Page 12: inserted 100 rows (total=1200)\n",
      "Page 13: inserted 100 rows (total=1300)\n",
      "Page 14: inserted 100 rows (total=1400)\n",
      "Page 15: inserted 100 rows (total=1500)\n",
      "Page 16: inserted 100 rows (total=1600)\n",
      "Page 17: inserted 100 rows (total=1700)\n",
      "Page 18: inserted 100 rows (total=1800)\n",
      "Page 19: inserted 100 rows (total=1900)\n",
      "Page 20: inserted 100 rows (total=2000)\n",
      "Page 21: inserted 100 rows (total=2100)\n",
      "Page 22: inserted 100 rows (total=2200)\n",
      "Page 23: inserted 100 rows (total=2300)\n",
      "Page 24: inserted 100 rows (total=2400)\n",
      "Page 25: inserted 100 rows (total=2500)\n",
      "ETL completed for 'Paintings', total=2500\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import pymysql\n",
    "\n",
    "\n",
    "HOST = \"localhost\"\n",
    "USER = \"root\"\n",
    "PASSWORD = \"\"\n",
    "DB_NAME = \"harvard_artifacts\"\n",
    "\n",
    "# ---------- API ----------\n",
    "API_KEY = \"20f6731f-61df-45d8-9a01-b48944b6ec56\"\n",
    "BASE_URL = \"https://api.harvardartmuseums.org\"\n",
    "\n",
    "# ---------- SQL ----------\n",
    "SQL_META = \"\"\"\n",
    "INSERT IGNORE INTO artifact_metadata\n",
    "(id, title, culture, period, century, medium, dimensions, description,\n",
    " department, classification, accessionyear, accessionmethod)\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "SQL_MEDIA = \"\"\"\n",
    "INSERT IGNORE INTO artifact_media\n",
    "(objectid, imagecount, mediacount, colorcount, rank, datebegin, dateend)\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "SQL_COLOR = \"\"\"\n",
    "INSERT IGNORE INTO artifact_colors\n",
    "(objectid, color, spectrum, hue, percent, css3)\n",
    "VALUES (%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "# ---------- DB Helper ----------\n",
    "def get_conn():\n",
    "    return pymysql.connect(host=HOST, user=USER, password=PASSWORD, database=DB_NAME)\n",
    "\n",
    "# ---------- Extract ----------\n",
    "def fetch_artifacts(classification=\"Paintings\", size=5, page=1):\n",
    "    \"\"\"Fetch artifacts from Harvard API (one page)\"\"\"\n",
    "    url = f\"{BASE_URL}/object\"\n",
    "    params = {\n",
    "        \"apikey\": API_KEY,\n",
    "        \"classification\": classification,\n",
    "        \"size\": size,\n",
    "        \"page\": page\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"records\", [])\n",
    "\n",
    "# ---------- Transform ----------\n",
    "def transform_records(records):\n",
    "    \"\"\"Transform JSON into tuples for SQL insertion\"\"\"\n",
    "    metadata_list, media_list, color_list = [], [], []\n",
    "\n",
    "    for obj in records:\n",
    "        oid = obj.get(\"objectid\")\n",
    "        if not oid:\n",
    "            continue\n",
    "\n",
    "        metadata_list.append((\n",
    "            oid, obj.get(\"title\"), obj.get(\"culture\"), obj.get(\"period\"),\n",
    "            obj.get(\"century\"), obj.get(\"medium\"), obj.get(\"dimensions\"),\n",
    "            obj.get(\"description\"), obj.get(\"department\"),\n",
    "            obj.get(\"classification\"), obj.get(\"accessionyear\"),\n",
    "            obj.get(\"accessionmethod\")\n",
    "        ))\n",
    "\n",
    "        media_list.append((\n",
    "            oid, obj.get(\"imagecount\"), obj.get(\"mediacount\"),\n",
    "            obj.get(\"colorcount\"), obj.get(\"rank\"),\n",
    "            obj.get(\"datebegin\"), obj.get(\"dateend\")\n",
    "        ))\n",
    "\n",
    "        for c in obj.get(\"colors\", []) or []:\n",
    "            color_list.append((\n",
    "                oid, c.get(\"color\"), c.get(\"spectrum\"),\n",
    "                c.get(\"hue\"), c.get(\"percent\"), c.get(\"css3\")\n",
    "            ))\n",
    "\n",
    "    return metadata_list, media_list, color_list\n",
    "\n",
    "# ---------- Load ----------\n",
    "def insert_into_db(metadata, media, colors):\n",
    "    conn = get_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    if metadata:\n",
    "        cur.executemany(SQL_META, metadata)\n",
    "    if media:\n",
    "        cur.executemany(SQL_MEDIA, media)\n",
    "    if colors:\n",
    "        cur.executemany(SQL_COLOR, colors)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(f\"Inserted {len(metadata)} metadata, {len(media)} media, {len(colors)} colors\")\n",
    "\n",
    "# ---------- ETL Pipeline (with pagination) ----------\n",
    "def run_etl_for_classification(classification=\"Paintings\", target=2500, page_size=100, pause=0.2):\n",
    "    total_inserted = 0\n",
    "    page = 1\n",
    "    conn = get_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        while total_inserted < target:\n",
    "            url = f\"{BASE_URL}/object\"\n",
    "            params = {\n",
    "                \"apikey\": API_KEY,\n",
    "                \"classification\": classification,\n",
    "                \"size\": page_size,\n",
    "                \"page\": page\n",
    "            }\n",
    "            r = requests.get(url, params=params, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "\n",
    "            records = data.get(\"records\", [])\n",
    "            if not records:\n",
    "                break\n",
    "\n",
    "            meta_batch, media_batch, color_batch = transform_records(records)\n",
    "            if meta_batch:\n",
    "                cur.executemany(SQL_META, meta_batch)\n",
    "            if media_batch:\n",
    "                cur.executemany(SQL_MEDIA, media_batch)\n",
    "            if color_batch:\n",
    "                cur.executemany(SQL_COLOR, color_batch)\n",
    "\n",
    "            conn.commit()\n",
    "            total_inserted += len(meta_batch)\n",
    "            print(f\"Page {page}: inserted {len(meta_batch)} rows (total={total_inserted})\")\n",
    "\n",
    "            info = data.get(\"info\", {})\n",
    "            if page >= info.get(\"pages\", 0):\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "            time.sleep(pause)\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "    print(f\"ETL completed for '{classification}', total={total_inserted}\")\n",
    "\n",
    "# ---------- Script Runner ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Test small batch\n",
    "     #raw = fetch_artifacts(\"Paintings\", size=5, page=1)\n",
    "     #meta, media, colors = transform_records(raw)\n",
    "     #insert_into_db(meta, media, colors)\n",
    "\n",
    "    # run full ETL\n",
    "    run_etl_for_classification(\"Paintings\", target=2500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
